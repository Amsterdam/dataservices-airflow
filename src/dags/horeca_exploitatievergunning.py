from typing import Final

import pandas as pd
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from common import default_args
from common.db import get_engine, get_ora_engine, wkt_loads_wrapped
from common.sql import SQL_CHECK_COUNT, SQL_CHECK_GEO
from contact_point.callbacks import get_contact_point_on_failure_callback
from geoalchemy2 import Geometry
from postgres_check_operator import PostgresCheckOperator
from postgres_permissions_operator import PostgresPermissionsOperator
from sqlalchemy.types import Date, Integer, Text

dag_id = "horeca_exploitatievergunning"

table_name = dag_id
table_name_new = f"{table_name}_new"
SQL_TABLE_RENAME: Final = f"""
    DROP TABLE IF EXISTS {table_name} CASCADE;
    ALTER TABLE {table_name_new} RENAME TO {table_name};
    ALTER TABLE {table_name} RENAME CONSTRAINT {table_name_new}_pkey TO {table_name}_pkey;
    ALTER INDEX ix_{table_name_new}_id RENAME TO ix_{table_name}_id;
    ALTER INDEX idx_{table_name_new}_locatie RENAME TO idx_{table_name}_locatie;
    ALTER INDEX idx_{table_name_new}_terrasgeometrie RENAME TO idx_{table_name}_terrasgeometrie;
"""


def load_from_dwh(table_name: str, source_srid: int) -> None:
    """Imports data from source into target database.

    Args:
        table_name: Name of target table to import data.
        source_srid: SRID of source.

    Executes:
        SQL statements
    """
    db_engine = get_engine()
    dwh_ora_engine = get_ora_engine("oracle_dwh_stadsdelen")
    with dwh_ora_engine.get_conn() as connection:
        df = pd.read_sql(
            """
            select ZAAKNUMMER
                , ZAAKNAAM
                , ADRES
                , ZAAK_CATEGORIE
                , ZAAK_SPECIFICATIE
                , BEGINDATUM
                , EINDDATUM
                , OPENINGSTIJDEN_ZO_DO_VAN
                , OPENINGSTIJDEN_ZO_DO_TOT
                , OPENINGSTIJDEN_VR_ZA_VAN
                , OPENINGSTIJDEN_VR_ZA_TOT
                , O_TIJDEN_TERRAS_ZO_DO_VAN
                , O_TIJDEN_TERRAS_ZO_DO_TOT
                , O_TIJDEN_TERRAS_VR_ZA_VAN
                , O_TIJDEN_TERRAS_VR_ZA_TOT
                , LOCATIE_WKT AS LOCATIE
                , TERRASGEOMETRIE_WKT AS TERRASGEOMETRIE
                , POSTCODE
                , STATUS_VERGUNNING
                , STATUS_TIJDELIJK_TERRAS
                , TOESTEMMING_TIJDELIJK_TERRAS
                , PUBL_BESLUIT_TIJDELIJK_TERRAS
                , TIJDELIJK_TERRAS_DETAILS
                , STATUS_VERLENG_TIJDELK_TERRAS
                , VERLENG_TIJDELK_TERRAS_DETAIL
            from DMDATA.HORECA_EXPLOITATIEVERGUNNING_V
        """,
            connection,
            coerce_float=True,
            params=None,
            parse_dates=["begindatum", "einddatum"],
            columns=None,
            chunksize=None,
        )
        # it seems that get_conn() makes the columns case sensitive
        # lowercase all columns so the database will handle them as case insensitive
        df.columns = map(str.lower, df.columns)
        df["locatie"] = df["locatie"].apply(func=wkt_loads_wrapped, source_srid=source_srid)
        df["terrasgeometrie"] = df["terrasgeometrie"].apply(
            func=wkt_loads_wrapped, source_srid=source_srid
        )
        dtype = {
            "zaaknummer": Integer(),
            "zaaknaam": Text(),
            "zaakcategorie": Text(),
            "zaakspecificatie": Text(),
            "begindatum": Date(),
            "einddatum": Date(),
            "openingstijden_zo_do_van": Text(),
            "openingstijden_zo_do_tot": Text(),
            "openingstijden_vr_za_van": Text(),
            "openingstijden_vr_za_tot": Text(),
            "o_tijden_terras_zo_do_van": Text(),
            "o_tijden_terras_zo_do_tot": Text(),
            "o_tijden_terras_vr_za_van": Text(),
            "o_tijden_terras_vr_za_tot": Text(),
            "locatie": Geometry(geometry_type="POINT", srid=source_srid),
            "terrasgeometrie": Geometry(geometry_type="MULTIPOLYGON", srid=source_srid),
            "postcode": Text(),
            "status_vergunning": Text(),
            "status_tijdelijk_terras": Text(),
            "toestemming_tijdelijk_terras": Text(),
            "publ_besluit_tijdelijk_terras": Text(),
            "tijdelijk_terras_details": Text(),
            "status_verleng_tijdelk_terras": Text(),
            "verleng_tijdelk_terras_detail": Text(),
        }
        df.to_sql(table_name, db_engine, if_exists="replace", index_label="id", dtype=dtype)
        with db_engine.connect() as connection:
            connection.execute("ALTER TABLE %s ADD PRIMARY KEY (id)", table_name)
            connection.execute(
                """
                 UPDATE %s
                 SET terrasgeometrie = ST_CollectionExtract(ST_Makevalid(terrasgeometrie), 3)
                 WHERE ST_IsValid(terrasgeometrie) = False;
             """,
                table_name,
            )
            if source_srid != 28992:
                connection.execute(
                    """
                    ALTER TABLE %s
                    ALTER COLUMN terrasgeometrie TYPE geometry(MultiPolygon,28992)
                    USING ST_Transform(terrasgeometrie,28992),
                    ALTER COLUMN locatie TYPE geometry(Point,28992)
                    USING ST_Transform(locatie,28992);
                """,
                    table_name,
                )
            connection.execute(
                """
                 ALTER TABLE %s RENAME COLUMN VERLENG_TIJDELK_TERRAS_DETAIL
                    to VERLENGING_TIJDELIJK_TERRAS_DETAILS;
                 ALTER TABLE %s RENAME COLUMN STATUS_VERLENG_TIJDELK_TERRAS
                    to STATUS_VERLENGING_TIJDELIJK_TERRAS;
             """,
                table_name,
            )


with DAG(
    "horeca_exploitatievergunning",
    default_args=default_args,
    description="Horeca Exploitatievergunning",
    schedule_interval="0 9 * * *",
    on_failure_callback=get_contact_point_on_failure_callback(dataset_id="horeca"),
) as dag:

    load_data = PythonOperator(
        task_id="load_data",
        python_callable=load_from_dwh,
        op_args=[table_name_new, 4326],
    )

    check_count = PostgresCheckOperator(
        task_id="check_count",
        sql=SQL_CHECK_COUNT,
        params={"tablename": table_name_new, "mincount": 4000},
    )

    check_geo1 = PostgresCheckOperator(
        task_id="check_geo1",
        sql=SQL_CHECK_GEO,
        params={
            "tablename": table_name_new,
            "geotype": "ST_MultiPolygon",
            "geo_column": "terrasgeometrie",
            "notnull": False,
        },
    )

    check_geo2 = PostgresCheckOperator(
        task_id="check_geo2",
        sql=SQL_CHECK_GEO,
        params={
            "tablename": table_name_new,
            "geotype": "ST_Point",
            "geo_column": "locatie",
            "notnull": False,
        },
    )

    rename_table = PostgresOperator(task_id="rename_table", sql=SQL_TABLE_RENAME)

    # Grant database permissions
    grant_db_permissions = PostgresPermissionsOperator(task_id="grants", dag_name=dag_id)

load_data >> check_count >> check_geo1 >> check_geo2 >> rename_table >> grant_db_permissions
